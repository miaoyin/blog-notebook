{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceph分布式文件系统环境搭建\n",
    "\n",
    "### 目的 \n",
    "\n",
    "在一台机器上, 利用多块硬盘, 搭建一个cephfs文件系统. 具体来说就是1个mon, 1个mds, 1个mgr, 3个osd\n",
    "\n",
    "### 注意\n",
    "\n",
    "a. 使用vmware会很方便\n",
    "\n",
    "b. 安装过程中会遇到很多问题，我都没有记录, 尽量安装下面步骤\n",
    "\n",
    "### 环境准备\n",
    "\n",
    "a. vmware虚拟机fedora30\n",
    "\n",
    "b. 添加3块虚拟机硬盘 /dev/sdb  /dev/sdc /dev/sdd (osd最少需要3个,需要有3块磁盘)\n",
    "\n",
    "c. ceph容器版本 ceph/daemon:latest-luminous\n",
    "\n",
    "\n",
    "### 搭建步骤\n",
    "\n",
    "1. 下载镜像\n",
    "\n",
    "```\n",
    "docker pull ceph/daemon:latest-luminous\n",
    "```\n",
    "\n",
    "2. 挂载硬盘\n",
    "vmware虚拟机添加硬盘很方便, 直接加就可以. fdisk -l 查看硬盘\n",
    "\n",
    "3. 清理硬盘\n",
    "\n",
    "```\n",
    "# 格式化\n",
    "mkfs.xfs /dev/sdb -f\n",
    "mkfs.xfs /dev/sdc -f\n",
    "mkfs.xfs /dev/sdd -f\n",
    "\n",
    "# 如果已经是xfs格式, 上面命令并不能清除已有数据, 需要用zap_device清理\n",
    "docker run -d --net=host --name=osd0  --rm \\\n",
    "--privileged=true \\\n",
    "-v /dev/:/dev/ \\\n",
    "-e OSD_DEVICE=/dev/sde  \\\n",
    " ceph/daemon:latest-luminous zap_device\n",
    "```\n",
    "\n",
    "4. 准备目录\n",
    "\n",
    "```\n",
    "/root/ceph\n",
    "/root/ceph/etc\n",
    "/root/ceph/lib\n",
    "```\n",
    "\n",
    "\n",
    "5. 启动mon (监控节点必需)\n",
    "\n",
    "```\n",
    "docker run -d --net=host  --name=mon \\\n",
    "-v /root/ceph/etc:/etc/ceph \\\n",
    "-v /root/ceph/lib/:/var/lib/ceph/ \\\n",
    "-e MON_IP=192.168.10.125 \\\n",
    "-e CEPH_PUBLIC_NETWORK=192.168.10.0/24 \\\n",
    " ceph/daemon:latest-luminous mon\n",
    "```\n",
    "\n",
    "6. 启动mgr(可以不用)\n",
    "\n",
    "```\n",
    "docker run -d --net=host --name=mgr \\\n",
    "-v /root/ceph/etc:/etc/ceph  \\\n",
    "-v /root/ceph/lib/:/var/lib/ceph  \\\n",
    "ceph/daemon:latest-luminous  mgr\n",
    "```\n",
    "\n",
    "7. 启动osd\n",
    "\n",
    "```\n",
    "# 修改-name和OSD_DEVICE启动三个osd\n",
    "docker run -d --net=host --name=osd0   \\\n",
    "--privileged=true \\\n",
    "-v /root/ceph/etc:/etc/ceph  \\\n",
    "-v /root/ceph/lib/:/var/lib/ceph  \\\n",
    "-v /dev/:/dev/ \\\n",
    "-e OSD_DEVICE=/dev/sdb  \\\n",
    "-e OSD_TYPE=disk \\\n",
    " ceph/daemon:latest-luminous osd\n",
    "```\n",
    "\n",
    "8. 启动mds(cephfs系统必需)\n",
    "\n",
    "```\n",
    "#  一定要在osd之后创建启动, 因为CEPHFS_CREATE=1会创建cephfs文件系统，受osd数量影响\n",
    "docker run -d --net=host --name=mds \\\n",
    "-v /root/ceph/etc:/etc/ceph \\\n",
    "-v /root/ceph/lib/:/var/lib/ceph/ \\\n",
    "-e CEPHFS_CREATE=1 \\      # 默认创建cephfs文件系统\n",
    "  ceph/daemon:latest-luminous mds\n",
    "```\n",
    "\n",
    "9. 进入mon查看ceph状态\n",
    "\n",
    "```\n",
    "# 进入容器\n",
    "docker exec -it mon bash\n",
    "\n",
    "# 查看状态\n",
    "[root@localhost /]# ceph -s\n",
    "  cluster:\n",
    "    id:     4d74fd53-84e0-47e6-a06c-5418e4b3b653\n",
    "    health: HEALTH_WARN\n",
    "            1 MDSs report slow metadata IOs\n",
    "            2 osds down\n",
    "            34/51 objects misplaced (66.667%)\n",
    "            Reduced data availability: 4 pgs inactive, 16 pgs stale\n",
    "            Degraded data redundancy: 16 pgs undersized\n",
    "            too few PGs per OSD (4 < min 30)\n",
    " \n",
    "  services:\n",
    "    mon: 1 daemons, quorum localhost\n",
    "    mgr: localhost(active)\n",
    "    mds: cephfs-1/1/1 up  {0=localhost=up:creating}\n",
    "    osd: 5 osds: 2 up, 4 in\n",
    " \n",
    "  data:\n",
    "    pools:   2 pools, 16 pgs\n",
    "    objects: 17 objects, 2.19KiB\n",
    "    usage:   4.01GiB used, 75.6GiB / 79.6GiB avail\n",
    "    pgs:     25.000% pgs not active\n",
    "             34/51 objects misplaced (66.667%)\n",
    "             12 stale+active+undersized+remapped\n",
    "             4  stale+undersized+peered\n",
    "```\n",
    "\n",
    "10. ceph调参: too few PGs per OSD (4 < min 30)\n",
    "\n",
    "存储池的pg_num, pgp_num太小了, 设置大一点\n",
    "\n",
    "```\n",
    "ceph osd pool set cephfs_data pg_num 64\n",
    "ceph osd pool set cephfs_data pgp_num 64\n",
    "ceph osd pool set  cephfs_metadata pg_num 32\n",
    "ceph osd pool set  cephfs_metadata pgp_num 32\n",
    "```\n",
    "\n",
    "11. ceph调参: mds: cephfs-1/1/1 up  {0=localhost=up:creating}\n",
    "\n",
    "mds一直处在creating状态, 因为默认I/O需要的最小副本数是2，我们需要调成1\n",
    "\n",
    "```\n",
    "ceph osd pool set cephfs_metadata min_size 1\n",
    "ceph osd pool set cephfs_data min_size 1\n",
    "```\n",
    "\n",
    "12. 再看ceph状态, mds状态是active表示cephfs搭建好了\n",
    "\n",
    "```\n",
    "mds: cephfs-1/1/1 up  {0=localhost=up:active}\n",
    "```\n",
    "\n",
    "13. 挂载cephfs目录(直接mount)\n",
    "\n",
    "```\n",
    "# 获取key\n",
    "cat /root/ceph/etc/ceph.client.admin.keyring\n",
    "# 直接挂载\n",
    "mount -t ceph 192.168.10.125:6789:/ /root/abc -o name=admin,secret=AQAvoctebqeuBRAAp+FoatmQ5CUlSlo8dmvGAg==\n",
    "# 取消挂载\n",
    "umount /root/abc\n",
    "```\n",
    "\n",
    "14. 挂载cephfs目录(ceph-fuse)\n",
    "\n",
    "```\n",
    "# 安装ceph-fuse\n",
    "yum install ceph-fuse\n",
    "\n",
    "# 挂载(-k指定key -c表示配置文件)\n",
    "ceph-fuse -m 192.168.10.125:6789 /root/abc1 -k /root/ceph/etc/ceph.client.admin.keyring  -c /root/ceph/etc/ceph.conf\n",
    "\n",
    "#取消挂载\n",
    "umount /root/abc1\n",
    "```\n",
    "\n",
    "15. 查看结果\n",
    "\n",
    "```\n",
    "df -h\n",
    "\n",
    "192.168.10.125:6789:/                     18G     0   18G    0% /root/abc\n",
    "ceph-fuse                                 18G     0   18G    0% /root/abc1\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
